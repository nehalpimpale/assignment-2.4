# assignment-2.4

Q1. Explain hadoop in layman's term

HDFS (Hadoop Distributed File System) – Abbreviated as HDFS, it is primarily a file system similar to many of the already existing ones. However, it is also a virtual file system.

There is one notable difference with other popular file systems, which is, when we move a file in HDFS, it is automatically split into smaller files. These smaller files are then replicated on a minimum of three different servers, so that they can be used as an alternative to unforeseen circumstances. This replication count isn’t necessarily hard-set, and can be decided upon as per requirements.

Hadoop MapReduce – MapReduce is mainly the programming aspect of Hadoop that allows processing of large volumes of data.

There is also a provision that breaks down requests into smaller requests, which are then sent to multiple servers. This allows utilization of the scalable power of the CPU.

Programming Languages – There are basically two programming languages that are identified as original Hadoop programming languages,
Hive
PIG
Besides these, there are a few other programming languages that can be used for writing programs, namely C, JAQL and Java. We can also make direct usage of SQL for interaction with the database, although that requires the use of standard JDBC or ODBC drivers.

Q2. Explain the components of Hadoop framework

Hadoop, as a whole, consists of the following parts:

Hadoop Distributed File System – Abbreviated as HDFS, it is primarily a file system similar to many of the already existing ones. However, it is also a virtual file system.

There is one notable difference with other popular file systems, which is, when we move a file in HDFS, it is automatically split into smaller files. These smaller files are then replicated on a minimum of three different servers, so that they can be used as an alternative to unforeseen circumstances. This replication count isn’t necessarily hard-set, and can be decided upon as per requirements.

Hadoop MapReduce – MapReduce is mainly the programming aspect of Hadoop that allows processing of large volumes of data.
There is also a provision that breaks down requests into smaller requests, which are then sent to multiple servers. This allows utilization of the scalable power of the CPU.

HBASE – HBASE happens to be a layer that sits atop the HDFS and has been developed by means of the Java programming language. HBASE primarily has the following aspects –
Non relational
Highly scalable
Fault tolerance
Every single row that exists in HBASE is identified by means of a key. The number of columns is also not defined, but rather grouped into column families.

Zookeeper – This is basically a centralized system that maintains –
Configuration information
Naming information
Synchronization information
Besides these, Zookeeper is also responsible for group services and is utilized by HBASE. It also comes to use for MapReduce programs.

Solr/Lucene – This is nothing but a search engine. Its libraries are developed by Apache and required over 10 years to be developed in its present robust form.

Programming Languages – There are basically two programming languages that are identified as original Hadoop programming languages,

Hive
PIG
Besides these, there are a few other programming languages that can be used for writing programs, namely C, JAQL and Java. We can also make direct usage of SQL for interaction with the database, although that requires the use of standard JDBC or ODBC drivers.


Q3. Eplain the reasons to learn Big data technologies 

Demand for Big Data skills is extremely high, and being able to prove your expertise is of essence
• 64% of IT hiring managers rate skilled big data knowledge as having extremely high or high value when rating expertise of candidates; this is based on a survey by CompTIA.
• According to Forbes, the median advertised salary for professionals with Big Data expertise is $124,000 a year.
• IBM, Cisco, and Oracle together advertised 26,488 open positions that required Big Data expertise in the last twelve months.

1.Data analytics is now a priority for top organizations

2.Increasing job opportunities

3.Increasing pay for data analytics professionals

4.Big data analytics is everywhere

5.You will have various job titles from which to choose
   -Metrics and Analytics Specialist
   -Data Analyst
   -Big Data Engineer
   -Data Analytics Consultant
   
6.You will be at the core of decision-making in the company

7.Adoption rate of big data analytics is high

8.Data analytics is taking over faster than expected

9.It represents perfect freelancing opportunities

10.Develop new revenue streams
